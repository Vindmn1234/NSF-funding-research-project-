{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lucem_illud\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file to a dataframe\n",
    "file_path = 'database/pub_info_2016_2022.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df.rename(columns={'Title': 'title', 'Year': 'award_year', 'Cited by': 'total_citation', 'Paper URL': 'url', 'Authors': 'authors', 'Publication Date': 'publication_date', 'Journal': 'journal', 'Abstract': 'abstract', 'Citations': 'yearly_citation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "df = df[['first_name', 'middle_name', 'last_name', 'email', 'title', 'journal', 'publication_date', 'authors', 'abstract', 'total_citation', 'yearly_citation', 'award_year', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'journal' column\n",
    "\n",
    "# drop rows where 'journal' is 'journal not found'\n",
    "#df = df[df['journal'] != 'journal not found']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'publication_date' column\n",
    "\n",
    "# option 1: drop rows where 'publication_date' is 'date not found'\n",
    "#df = df[df['publication_date'] != 'date not found']\n",
    "\n",
    "# option 2: replace 'date not found' in 'publication_date' with 'year/1/1'\n",
    "def replace_date(row):\n",
    "    if row['publication_date'] == 'date not found':\n",
    "        return f\"{row['year']}/1/1\"\n",
    "    else:\n",
    "        return row['publication_date']\n",
    "\n",
    "# apply the function\n",
    "df['publication_date'] = df.apply(replace_date, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure 'publication_date' column are strings\n",
    "#df['publication_date'] = df['publication_date'].astype(str)\n",
    "\n",
    "# option 1: convert 'year' format to 'year/1/1' format\n",
    "#df['publication_date'] = df['publication_date'].apply(lambda x: f\"{x}/1/1\" if x.isdigit() else x)\n",
    "\n",
    "# option 2: drop rows where 'publication_date' only contains year\n",
    "#df = df[~df['publication_date'].str.isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'authors' column\n",
    "\n",
    "# convert each row in 'authors' to a list of authors\n",
    "df['authors'] = df['authors'].str.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'total_citation' column\n",
    "\n",
    "# option 1: replace missing values in 'total_citation' with 0\n",
    "#df['total_citation'] = df['total_citation'].fillna(0) \n",
    "\n",
    "# option 2: drop rows where 'total_citation' is missing\n",
    "#df = df.dropna(subset=['total_citation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'yearly_citation' column\n",
    "\n",
    "# option 1: drop rows where 'yearly_citation' column contains an empty dictionary\n",
    "#df = df[df['yearly_citation'].apply(lambda x: x != {})]\n",
    "\n",
    "# option 2: update rows with an empty dictionary in 'yearly_citation' using 'award_year' as key and 'total_citation' as value\n",
    "#df['yearly_citation'] = df.apply(lambda row: {row['award_year']: row['total_citation']} if row['yearly_citation'] == {} else row['yearly_citation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean 'abstract' column\n",
    "\n",
    "# drop rows where 'abstract' is 'abstract not found' \n",
    "df = df[df['abstract'] != 'abstract not found']\n",
    "\n",
    "# drop rows where 'abstract' has fewer than 20 words \n",
    "df = df[df['abstract'].astype(str).str.split().apply(len) >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each author name to lowercase\n",
    "df['authors'] = df['authors'].apply(lambda x: [name.lower() for name in x])\n",
    "\n",
    "# convert each journal name to lowercase\n",
    "df['journal'] = df['journal'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize 'title' column\n",
    "df['tokenized_title'] = df['title'].progress_apply(lambda x: [lucem_illud.word_tokenize(s) for s in lucem_illud.sent_tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 'tokenized_title' column\n",
    "df['normalized_title'] = df['tokenized_title'].apply(lambda x: [lucem_illud.normalizeTokens(s) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize 'abstract' column\n",
    "df['tokenized_abstract'] = df['abstract'].progress_apply(lambda x: [lucem_illud.word_tokenize(s) for s in lucem_illud.sent_tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomalize 'tokenized_abstract' column\n",
    "df['normalized_abstract'] = df['tokenized_abstract'].apply(lambda x: [lucem_illud.normalizeTokens(s) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign data types\n",
    "df = df.astype({'first_name': 'object', 'middle_name': 'object', 'last_name': 'object', 'email': 'object'})\n",
    "df = df.astype({'title': 'object', 'journal': 'object', 'authors': 'object', 'abstract': 'object'})\n",
    "df = df.astype({'total_citation': 'int64', 'yearly_citation': 'object', 'award_year': 'category', 'url': 'object'})\n",
    "df['publication_date'] = pd.to_datetime(df['publication_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv file\n",
    "file_path = 'database/cleaned_pub_info_2016_2022.csv'\n",
    "df.to_csv(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
