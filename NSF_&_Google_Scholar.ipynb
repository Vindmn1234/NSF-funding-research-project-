{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZA8dVFisev0"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l43IGp9nseLY",
        "outputId": "bbcea147-ac79-4a9b-aee6-a2a49f6955a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from lxml import etree\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
        "import time\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Set up Chromdriver for Dynamic Scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "8BtTtyhLMosy",
        "outputId": "3beca6a0-7529-417b-be44-ceebbf02b4f5"
      },
      "outputs": [],
      "source": [
        "# Set up chromedriver\n",
        "!pip install chromedriver-autoinstaller\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "import chromedriver_autoinstaller\n",
        "\n",
        "# set path to chromedriver as per your configuration\n",
        "chromedriver_autoinstaller.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d14toXYsmiy"
      },
      "source": [
        "# Load NSF data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jQKkrUnhrLjN"
      },
      "outputs": [],
      "source": [
        "# Unzip the file\n",
        "\n",
        "# Create the main directory to store OSF data (xml files) if it doesn't exist\n",
        "if not os.path.isdir(\"NSF_data\"):\n",
        "    os.mkdir(\"NSF_data\")\n",
        "\n",
        "# Unzip the file into a subdirectory\n",
        "if not os.path.isdir(\"NSF_data/2018\"):\n",
        "    with zipfile.ZipFile(\"NSF_zip/2018.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"NSF_data/2018\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9VGY9EitlcC"
      },
      "source": [
        "This is a website introducing the directory and affiliated divisions: https://new.nsf.gov/about/directorates-offices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yuS5685Q793Y"
      },
      "outputs": [],
      "source": [
        "# Extracts data from downloaded NSF files\n",
        "def extract_data_from_file(file_path):\n",
        "    tree = etree.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    extracted_data = {\n",
        "        \"first_name\": \"\",\n",
        "        \"middle_name\": \"\",\n",
        "        \"last_name\": \"\",\n",
        "        \"email\": \"\",\n",
        "        \"directorate\": \"\",\n",
        "        \"division\": \"\",\n",
        "        \"effective_date\": \"\",\n",
        "        \"expiration_date\": \"\",\n",
        "        \"award_amount\": \"\",\n",
        "        \"abstract\": \"\"\n",
        "    }\n",
        "\n",
        "    award = root.find('Award')\n",
        "\n",
        "    extracted_data[\"effective_date\"] = award.findtext('AwardEffectiveDate') or ''\n",
        "    extracted_data[\"expiration_date\"] = award.findtext('AwardExpirationDate') or ''\n",
        "    extracted_data[\"award_amount\"] = award.findtext('AwardTotalIntnAmount') or ''\n",
        "    extracted_data[\"abstract\"] = award.findtext('AbstractNarration') or ''\n",
        "    extracted_data[\"directorate\"] = award.findtext('Organization/Directorate/LongName') or ''\n",
        "    extracted_data[\"division\"] = award.findtext('Organization/Division/LongName') or ''\n",
        "    extracted_data[\"first_name\"] = award.findtext('Investigator/FirstName') or ''\n",
        "    extracted_data[\"middle_name\"] = award.findtext('Investigator/PI_MID_INIT') or ''\n",
        "    extracted_data[\"last_name\"] = award.findtext('Investigator/LastName') or ''\n",
        "    extracted_data[\"email\"] = award.findtext('Investigator/EmailAddress') or ''\n",
        "\n",
        "    return extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processes files in a folder\n",
        "def process_folder(folder_path, filter_directorate):\n",
        "    all_data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.xml'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            data = extract_data_from_file(file_path)\n",
        "            if data[\"directorate\"] == filter_directorate:\n",
        "              all_data.append(data)\n",
        "\n",
        "    return pd.DataFrame(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UsTEQqGC8eyh"
      },
      "outputs": [],
      "source": [
        "# example use for extracting\n",
        "folder_path = 'NSF_data/2018' # path to folder where NSF files are stored\n",
        "file_path = 'funding_info_2018.csv'\n",
        "\n",
        "if os.path.isfile(file_path):\n",
        "  nsf_df = pd.read_csv(file_path)\n",
        "else:\n",
        "  nsf_df = process_folder(folder_path, filter_directorate=\"Direct For Social, Behav & Economic Scie\") # process the folder\n",
        "  nsf_df.to_csv(file_path, index=False) # save the dataframe in a csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vahCdjONw_x8",
        "outputId": "3ee02e51-8c67-4a11-d699-8acbac06d2a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_name</th>\n",
              "      <th>middle_name</th>\n",
              "      <th>last_name</th>\n",
              "      <th>email</th>\n",
              "      <th>directorate</th>\n",
              "      <th>division</th>\n",
              "      <th>effective_date</th>\n",
              "      <th>expiration_date</th>\n",
              "      <th>award_amount</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keith</td>\n",
              "      <td>M</td>\n",
              "      <td>Murphy</td>\n",
              "      <td>kmmurphy@uci.edu</td>\n",
              "      <td>Direct For Social, Behav &amp; Economic Scie</td>\n",
              "      <td>Division Of Behavioral and Cognitive Sci</td>\n",
              "      <td>03/01/2019</td>\n",
              "      <td>02/29/2024</td>\n",
              "      <td>209801.00</td>\n",
              "      <td>Communication among humans is known to be comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scott</td>\n",
              "      <td></td>\n",
              "      <td>StGeorge</td>\n",
              "      <td>stgeorge@umn.edu</td>\n",
              "      <td>Direct For Social, Behav &amp; Economic Scie</td>\n",
              "      <td>Division Of Behavioral and Cognitive Sci</td>\n",
              "      <td>09/01/2018</td>\n",
              "      <td>04/30/2023</td>\n",
              "      <td>349934.00</td>\n",
              "      <td>This research project will examine the degree ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shauna</td>\n",
              "      <td>M</td>\n",
              "      <td>Cooper</td>\n",
              "      <td>scooper1@live.unc.edu</td>\n",
              "      <td>Direct For Social, Behav &amp; Economic Scie</td>\n",
              "      <td>Division Of Behavioral and Cognitive Sci</td>\n",
              "      <td>07/01/2017</td>\n",
              "      <td>06/30/2019</td>\n",
              "      <td>96141.00</td>\n",
              "      <td>Little is known about African American fathers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alan</td>\n",
              "      <td>C</td>\n",
              "      <td>Yu</td>\n",
              "      <td>aclyu@uchicago.edu</td>\n",
              "      <td>Direct For Social, Behav &amp; Economic Scie</td>\n",
              "      <td>Division Of Behavioral and Cognitive Sci</td>\n",
              "      <td>09/15/2018</td>\n",
              "      <td>02/29/2020</td>\n",
              "      <td>30648.00</td>\n",
              "      <td>Language change is inevitable and constant: al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wilson</td>\n",
              "      <td></td>\n",
              "      <td>Silva</td>\n",
              "      <td>wdelimasilva@email.arizona.edu</td>\n",
              "      <td>Direct For Social, Behav &amp; Economic Scie</td>\n",
              "      <td>Division Of Behavioral and Cognitive Sci</td>\n",
              "      <td>06/01/2018</td>\n",
              "      <td>12/31/2020</td>\n",
              "      <td>90383.00</td>\n",
              "      <td>A finely balanced linguistic ecology is needed...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  first_name middle_name last_name                           email  \\\n",
              "0      Keith           M    Murphy                kmmurphy@uci.edu   \n",
              "1      Scott              StGeorge                stgeorge@umn.edu   \n",
              "2     Shauna           M    Cooper           scooper1@live.unc.edu   \n",
              "3       Alan           C        Yu              aclyu@uchicago.edu   \n",
              "4     Wilson                 Silva  wdelimasilva@email.arizona.edu   \n",
              "\n",
              "                                directorate  \\\n",
              "0  Direct For Social, Behav & Economic Scie   \n",
              "1  Direct For Social, Behav & Economic Scie   \n",
              "2  Direct For Social, Behav & Economic Scie   \n",
              "3  Direct For Social, Behav & Economic Scie   \n",
              "4  Direct For Social, Behav & Economic Scie   \n",
              "\n",
              "                                   division effective_date expiration_date  \\\n",
              "0  Division Of Behavioral and Cognitive Sci     03/01/2019      02/29/2024   \n",
              "1  Division Of Behavioral and Cognitive Sci     09/01/2018      04/30/2023   \n",
              "2  Division Of Behavioral and Cognitive Sci     07/01/2017      06/30/2019   \n",
              "3  Division Of Behavioral and Cognitive Sci     09/15/2018      02/29/2020   \n",
              "4  Division Of Behavioral and Cognitive Sci     06/01/2018      12/31/2020   \n",
              "\n",
              "  award_amount                                           abstract  \n",
              "0    209801.00  Communication among humans is known to be comp...  \n",
              "1    349934.00  This research project will examine the degree ...  \n",
              "2     96141.00  Little is known about African American fathers...  \n",
              "3     30648.00  Language change is inevitable and constant: al...  \n",
              "4     90383.00  A finely balanced linguistic ecology is needed...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nsf_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHPPyO19xC00",
        "outputId": "eb76fbd0-3724-476a-835b-5437284e9929"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Division Of Behavioral and Cognitive Sci    481\n",
              "Divn Of Social and Economic Sciences        388\n",
              "SBE Off Of Multidisciplinary Activities      87\n",
              "National Center For S&E Statistics            8\n",
              "Name: division, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nsf_df[\"division\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5w1mSiSvbL3"
      },
      "source": [
        "# Dynamically scrape the publishing-related info about the author on the NSF award list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCiGI7G4v0kI"
      },
      "source": [
        "## Define helper functions to dynamically scrape citation metrics, publication details, and research interests of a given author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nFdtOrQgwHFj"
      },
      "outputs": [],
      "source": [
        "# Finds Google Scholar urls\n",
        "def find_url(driver, full_name, email_domain):\n",
        "    url = f\"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors={full_name}\"\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    authors = driver.find_elements(By.CSS_SELECTOR, \"div.gs_ai.gs_scl.gs_ai_chpr\")\n",
        "    for author in authors:\n",
        "        author_email_text = author.find_element(By.CSS_SELECTOR, \"div.gs_ai_eml\").text\n",
        "        if 'Verified email at ' in author_email_text:\n",
        "            author_email_domain = author_email_text.split('Verified email at ')[1]\n",
        "            if email_domain == author_email_domain:\n",
        "                link_element = author.find_element(By.CSS_SELECTOR, \"a.gs_ai_pho\")\n",
        "                return link_element.get_attribute('href')\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "# Finds citations\n",
        "def find_citations(driver, url):\n",
        "    driver.set_window_size(800, 1000)\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    cited_by_tab = driver.find_element(By.ID, \"gsc_prf_t-cit\")\n",
        "    cited_by_tab.click()\n",
        "    time.sleep(3)\n",
        "\n",
        "    total_citations = driver.find_element(By.XPATH, '//*[@id=\"gsc_rsb_st\"]/tbody/tr[1]/td[2]').text\n",
        "    h_index = driver.find_element(By.XPATH, '//*[@id=\"gsc_rsb_st\"]/tbody/tr[2]/td[2]').text\n",
        "\n",
        "    year_citations = {}\n",
        "    year_elements = driver.find_elements(By.CSS_SELECTOR, \"div.gsc_md_hist_w .gsc_g_t\")\n",
        "    citation_elements = driver.find_elements(By.CSS_SELECTOR, \"div.gsc_md_hist_w .gsc_g_a\")\n",
        "\n",
        "    for year, citation in zip(year_elements, citation_elements):\n",
        "        citation_count = driver.execute_script(\"return arguments[0].textContent\", citation)\n",
        "        year_citations[year.text] = citation_count\n",
        "\n",
        "    return total_citations, h_index, year_citations\n",
        "\n",
        "\n",
        "# Finds publications => retreive not only the tile of the publication, \n",
        "# but also its citation count, year of publication, and paper abstract\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "def find_publications(driver, url):\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            show_more_button = driver.find_element(By.ID, \"gsc_bpf_more\")\n",
        "            if show_more_button.is_displayed() and show_more_button.is_enabled():\n",
        "                show_more_button.click()\n",
        "                time.sleep(2)\n",
        "            else:\n",
        "                break\n",
        "        except (NoSuchElementException, ElementClickInterceptedException):\n",
        "            break\n",
        "\n",
        "    publications = []\n",
        "    rows = driver.find_elements(By.CSS_SELECTOR, \"tr.gsc_a_tr\")\n",
        "\n",
        "    for row in rows:\n",
        "        # Extract title\n",
        "        title_element = row.find_element(By.CSS_SELECTOR, \"a.gsc_a_at\")\n",
        "        title = title_element.text\n",
        "\n",
        "        # Extract coauthors\n",
        "        coauthors_element = row.find_elements(By.CSS_SELECTOR, \"td.gsc_a_t div.gs_gray\")[0]\n",
        "        coauthors = coauthors_element.text if coauthors_element else \"Coauthors not found\"\n",
        "\n",
        "        # Extract citation count\n",
        "        citation_element = row.find_element(By.CSS_SELECTOR, \"td.gsc_a_c a.gsc_a_ac.gs_ibl\")\n",
        "        n_citation = citation_element.text if citation_element else \"0\"\n",
        "\n",
        "        # Extract year of publication\n",
        "        year_element = row.find_element(By.CSS_SELECTOR, \"td.gsc_a_y span.gsc_a_h.gsc_a_hc.gs_ibl\")\n",
        "        year = year_element.text if year_element else \"Year not found\"\n",
        "\n",
        "        # Navigate to the citation link page to extract abstract\n",
        "        publication_url = title_element.get_attribute('href')\n",
        "        driver.get(publication_url)\n",
        "        time.sleep(3)  # Wait for the page to load\n",
        "\n",
        "        # Extract the abstract\n",
        "        try:\n",
        "            abstract_element = driver.find_element(By.CSS_SELECTOR, \"div.gsh_csp\") # div.gsh_small\n",
        "            abstract = abstract_element.text\n",
        "        except NoSuchElementException:\n",
        "            abstract = \"Abstract not found\"\n",
        "\n",
        "        driver.back()\n",
        "\n",
        "        publications.append({\n",
        "            \"title\": title,\n",
        "            \"year\": year,\n",
        "            \"coauthors\": coauthors,\n",
        "            \"n_citation\": n_citation,\n",
        "            \"abstract\": abstract\n",
        "        })\n",
        "\n",
        "    return publications\n",
        "\n",
        "# Finds interests\n",
        "def find_interests(driver, url):\n",
        "    driver.get(url)\n",
        "    time.sleep(3)\n",
        "\n",
        "    interests = []\n",
        "\n",
        "    try:\n",
        "        interest = driver.find_elements(By.CSS_SELECTOR, \"div#gsc_prf_int a.gsc_prf_inta\")\n",
        "        interests = [i.text for i in interest] if interest else None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred: {e}\")\n",
        "\n",
        "    return interests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaFSM2PuwJAc"
      },
      "source": [
        "## Define the function that scrapes publishing info of authors by relating to the `nsf_data` dataframe just created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HzZEjDlo7oIx"
      },
      "outputs": [],
      "source": [
        "# Cleans and updates the dataframe\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "\n",
        "def update_and_save_dataframe(df, chrome_driver_path):\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')  # Ensure GUI is off\n",
        "    chrome_options.add_argument('--no-sandbox')  # Bypass OS security model\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')  # Overcome limited resource problems\n",
        "\n",
        "    # Set up ChromeService using the specified path\n",
        "    service = ChromeService(executable_path=chrome_driver_path)\n",
        "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "\n",
        "    # Updates Google Scholar urls\n",
        "    df = df.dropna(subset=['email'])\n",
        "    df['url'] = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        full_name = f\"{row['first_name']} {row['middle_name']} {row['last_name']}\".strip() if pd.notna(row['middle_name']) else f\"{row['first_name']} {row['last_name']}\"\n",
        "        email_domain = row['email'].split('@')[-1]\n",
        "        url = find_url(driver, full_name, email_domain)\n",
        "        df.loc[index, 'url'] = url\n",
        "        time.sleep(3)\n",
        "\n",
        "    df = df.dropna(subset=['url'])\n",
        "    df['publications'] = None\n",
        "    df['interests'] = None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        url = row['url']\n",
        "\n",
        "        # Updates citations\n",
        "        total_citations, h_index, year_citations = find_citations(driver, url)\n",
        "        df.at[index, 'total_citations'] = total_citations\n",
        "        df.at[index, 'h_index'] = h_index\n",
        "\n",
        "        for year, citations in year_citations.items():\n",
        "            col_name = f'citations_{year}'\n",
        "            df.at[index, col_name] = citations\n",
        "\n",
        "        # Updates publications\n",
        "        publications = find_publications(driver, url)\n",
        "        df.at[index, 'publications'] = publications # For now I store the whole dictionary of title, n_citation, year, and abstract in a whole cell (which definitely could be improved in future)\n",
        "\n",
        "        # Updates interests\n",
        "        interests = find_interests(driver, url)\n",
        "        if interests:\n",
        "            df.at[index, 'interests'] = [interest for interest in interests]\n",
        "\n",
        "        time.sleep(3)\n",
        "\n",
        "    driver.quit()\n",
        "\n",
        "    df.to_csv('publication_info_2018.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0fXtjhYB7oIz"
      },
      "outputs": [],
      "source": [
        "# Define path to chromedriver\n",
        "chrome_driver_path = 'chromedriver-mac-x64/chromedriver'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OYxvR4V0Ednx",
        "outputId": "0408f3e1-fd34-4484-e6a7-cc08b5f151a0"
      },
      "outputs": [
        {
          "ename": "StaleElementReferenceException",
          "evalue": "Message: stale element reference: stale element not found\n  (Session info: chrome-headless-shell=121.0.6167.139); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n0   chromedriver                        0x0000000100962168 chromedriver + 4673896\n1   chromedriver                        0x00000001009599c3 chromedriver + 4639171\n2   chromedriver                        0x000000010054dfdd chromedriver + 397277\n3   chromedriver                        0x000000010055d803 chromedriver + 460803\n4   chromedriver                        0x000000010055426a chromedriver + 422506\n5   chromedriver                        0x000000010055246e chromedriver + 414830\n6   chromedriver                        0x000000010055579f chromedriver + 427935\n7   chromedriver                        0x000000010055584c chromedriver + 428108\n8   chromedriver                        0x0000000100599a03 chromedriver + 707075\n9   chromedriver                        0x0000000100599dd1 chromedriver + 708049\n10  chromedriver                        0x000000010058e156 chromedriver + 659798\n11  chromedriver                        0x00000001005bc8ed chromedriver + 850157\n12  chromedriver                        0x000000010058e038 chromedriver + 659512\n13  chromedriver                        0x00000001005bca7e chromedriver + 850558\n14  chromedriver                        0x00000001005db796 chromedriver + 976790\n15  chromedriver                        0x00000001005bc663 chromedriver + 849507\n16  chromedriver                        0x000000010058c1cf chromedriver + 651727\n17  chromedriver                        0x000000010058d1ae chromedriver + 655790\n18  chromedriver                        0x0000000100922380 chromedriver + 4412288\n19  chromedriver                        0x0000000100927798 chromedriver + 4433816\n20  chromedriver                        0x0000000100906d71 chromedriver + 4300145\n21  chromedriver                        0x00000001009284e6 chromedriver + 4437222\n22  chromedriver                        0x00000001008f8d3c chromedriver + 4242748\n23  chromedriver                        0x0000000100948208 chromedriver + 4567560\n24  chromedriver                        0x00000001009483be chromedriver + 4567998\n25  chromedriver                        0x0000000100959603 chromedriver + 4638211\n26  libsystem_pthread.dylib             0x00007ff80bda71d3 _pthread_start + 125\n27  libsystem_pthread.dylib             0x00007ff80bda2bd3 thread_start + 15\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# example use\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m update_and_save_dataframe(nsf_df[:\u001b[38;5;241m1\u001b[39m], chrome_driver_path)\n",
            "Cell \u001b[0;32mIn[19], line 42\u001b[0m, in \u001b[0;36mupdate_and_save_dataframe\u001b[0;34m(df, chrome_driver_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m     df\u001b[38;5;241m.\u001b[39mat[index, col_name] \u001b[38;5;241m=\u001b[39m citations\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Updates publications\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m publications \u001b[38;5;241m=\u001b[39m find_publications(driver, url)\n\u001b[1;32m     43\u001b[0m df\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublications\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m publications \u001b[38;5;66;03m# For now I store the whole dictionary of title, n_citation, year, and abstract in a whole cell (which definitely could be improved in future)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Updates interests\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[18], line 66\u001b[0m, in \u001b[0;36mfind_publications\u001b[0;34m(driver, url)\u001b[0m\n\u001b[1;32m     62\u001b[0m rows \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr.gsc_a_tr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Extract title\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     title_element \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma.gsc_a_at\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     title \u001b[38;5;241m=\u001b[39m title_element\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Extract coauthors\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webelement.py:417\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    414\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    415\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mFIND_CHILD_ELEMENT, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/webdriver.py:348\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    346\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[1;32m    349\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/selenium/webdriver/remote/errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
            "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: stale element not found\n  (Session info: chrome-headless-shell=121.0.6167.139); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\nStacktrace:\n0   chromedriver                        0x0000000100962168 chromedriver + 4673896\n1   chromedriver                        0x00000001009599c3 chromedriver + 4639171\n2   chromedriver                        0x000000010054dfdd chromedriver + 397277\n3   chromedriver                        0x000000010055d803 chromedriver + 460803\n4   chromedriver                        0x000000010055426a chromedriver + 422506\n5   chromedriver                        0x000000010055246e chromedriver + 414830\n6   chromedriver                        0x000000010055579f chromedriver + 427935\n7   chromedriver                        0x000000010055584c chromedriver + 428108\n8   chromedriver                        0x0000000100599a03 chromedriver + 707075\n9   chromedriver                        0x0000000100599dd1 chromedriver + 708049\n10  chromedriver                        0x000000010058e156 chromedriver + 659798\n11  chromedriver                        0x00000001005bc8ed chromedriver + 850157\n12  chromedriver                        0x000000010058e038 chromedriver + 659512\n13  chromedriver                        0x00000001005bca7e chromedriver + 850558\n14  chromedriver                        0x00000001005db796 chromedriver + 976790\n15  chromedriver                        0x00000001005bc663 chromedriver + 849507\n16  chromedriver                        0x000000010058c1cf chromedriver + 651727\n17  chromedriver                        0x000000010058d1ae chromedriver + 655790\n18  chromedriver                        0x0000000100922380 chromedriver + 4412288\n19  chromedriver                        0x0000000100927798 chromedriver + 4433816\n20  chromedriver                        0x0000000100906d71 chromedriver + 4300145\n21  chromedriver                        0x00000001009284e6 chromedriver + 4437222\n22  chromedriver                        0x00000001008f8d3c chromedriver + 4242748\n23  chromedriver                        0x0000000100948208 chromedriver + 4567560\n24  chromedriver                        0x00000001009483be chromedriver + 4567998\n25  chromedriver                        0x0000000100959603 chromedriver + 4638211\n26  libsystem_pthread.dylib             0x00007ff80bda71d3 _pthread_start + 125\n27  libsystem_pthread.dylib             0x00007ff80bda2bd3 thread_start + 15\n"
          ]
        }
      ],
      "source": [
        "# example use\n",
        "update_and_save_dataframe(nsf_df[:1], chrome_driver_path) # updates and saves the dataframe into a new csv file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
